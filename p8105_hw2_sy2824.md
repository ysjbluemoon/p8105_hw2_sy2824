p8015\_hw2\_sy2824
================
Sijia Yue

Problem 1
=========

Data cleaning
-------------

``` r
subway_data = 
  read.csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line:vending, ada) %>%
  select(-exit_only) %>%
  mutate(entry = recode(entry,"YES" = "TRUE", "NO" = "FALSE")) %>%
  mutate(vending = recode(vending, "YES" = "TRUE", "NO" = "FALSE")) 
```

-   Read csv file into R and cleaned the format of variable names.
-   Delete the unrelating coloums according to the question.
-   Delete the exit\_only coloum since it is completely related to the coloum "entry".
-   Change the "entry" and "vending" coloum from charater to logical.
-   The dimisention of this dataset is 1868, 19.
-   This is not a tidy dataset because the variable `route` appears eleven times in the varibles row, this problem should be fixed.

**How many distinct stations?**

``` r
distinct(subway_data,line,station_name) %>%
nrow()
```

    ## [1] 465

There are 465 distinct stations.

**How many stations are ADA compliant?**

``` r
filter(subway_data,ada == "TRUE") %>%
distinct(line, station_name) %>%  
nrow()
```

    ## [1] 84

There are 84 ADA compliant.

**What proportion of station entrances / exits without vending allow entrance?**

``` r
num_entry_without_vending = nrow(filter(subway_data, entry == "TRUE",vending == "FALSE")) 
proportion = num_entry_without_vending/nrow(filter(subway_data,vending == "FALSE"))
proportion
```

    ## [1] 0.3770492

The proportion of station entrances / exits without vending is 0.377

Reformat data
-------------

Since the `route` variable has eleven corresponding variables on the first row, I would use the function `gather()` to gather the route information into a new variable called`route_number`.

``` r
tidy_subway_data =
  gather(subway_data,key = route_number, value = route_served, route1:route11) %>%
  filter(route_served != 'NA') %>% 
  select(-route_number)
```

**How many distinct stations serve the A train? How many are ADA compliant?**

``` r
filter(tidy_subway_data, route_served == "A") %>%
  distinct(station_name, line) %>%
  nrow()
```

    ## [1] 60

``` r
filter(tidy_subway_data, route_served == "A") %>%
  filter(ada == "TRUE") %>%
  distinct(station_name, line) %>%
  nrow()
```

    ## [1] 17

There are 60 distinct stations serve the A train. 17 of them have ADA complaint.

Problem 2
=========

Data cleaning
-------------

``` r
trash_wheel_data = 
  read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>%
  rename("number" = "dumpster",  "weight" = "weight_tons" , "volume" = "volume_cubic_yards")  %>% 
  filter(number != "NA")  
  
trash_wheel_data$sports_balls = as.integer(trash_wheel_data$sports_balls)
```

``` r
precipitation_2016_data = 
  read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2016 Precipitation", range = 'A2:B15') %>%
  janitor::clean_names() %>% 
  filter(month != "NA") %>% 
  mutate(year = 2016) 
  
precipitation_2017_data = 
  read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2017 Precipitation", range = 'A2:B15') %>%
  janitor::clean_names() %>% 
  filter(month != "NA") %>% 
  mutate(year = 2017) 
    
precipitation_data = 
  bind_rows(precipitation_2016_data, precipitation_2017_data)  %>% 
  mutate(month = month.name[month]) %>% 
  select(year, month, total)
```

**What was the total precipitation in 2017? **

``` r
total_2017_data = filter(precipitation_data, year == "2017", total != "NA")
total_2017 = sum(total_2017_data$total)
```

The total precipitation in 2017 is 32.93 tons.

**What was the median number of sports balls in a dumpster in 2016?**

``` r
filter(trash_wheel_data, year == "2016", sports_balls != "NA")
```

    ## # A tibble: 51 x 14
    ##    number month  year date                weight volume plastic_bottles
    ##     <dbl> <chr> <dbl> <dttm>               <dbl>  <dbl>           <dbl>
    ##  1    116 Janu~  2016 2016-01-10 00:00:00   3.6      15            3240
    ##  2    117 Febr~  2016 2016-02-02 00:00:00   4.06     18            3530
    ##  3    118 Febr~  2016 2016-02-03 00:00:00   2.11     15            2340
    ##  4    119 Febr~  2016 2016-02-05 00:00:00   3.01     15            2460
    ##  5    120 Febr~  2016 2016-02-17 00:00:00   3.41     18            1340
    ##  6    121 Febr~  2016 2016-02-19 00:00:00   3.66     15             950
    ##  7    122 Febr~  2016 2016-02-25 00:00:00   4.51     15            2240
    ##  8    123 March  2016 2016-03-01 00:00:00   2.89     18            3050
    ##  9    124 March  2016 2016-03-11 00:00:00   2.89     15            1630
    ## 10    125 March  2016 2016-03-12 00:00:00   2.51     15            1120
    ## # ... with 41 more rows, and 7 more variables: polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, grocery_bags <dbl>,
    ## #   chip_bags <dbl>, sports_balls <int>, homes_powered <dbl>

``` r
sports_balls_2016_median = median(trash_wheel_data$sports_balls)
```

The median number of sports balls in a dumpster in 2016 is 8.

Problem 3
=========

``` r
tidy_brfss = 
  brfss_smart2010 %>%
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  select(-class, -topic, -question, -sample_size, -(confidence_limit_low:geo_location))

structured_brfss = 
  spread(tidy_brfss, key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(sum = excellent + fair + good + poor + very_good) %>% 
  mutate(proportion = (excellent + very_good)/sum) 
```

**How many unique locations are included in the dataset? Is every state represented? What state is observed the most?**

``` r
distinct(structured_brfss,locationabbr, locationdesc) %>% 
  nrow()
```

    ## [1] 404

``` r
distinct(structured_brfss, locationabbr) %>% 
  nrow()
```

    ## [1] 51

``` r
count(structured_brfss,locationabbr) %>% 
  arrange(desc(n))
```

    ## # A tibble: 51 x 2
    ##    locationabbr     n
    ##    <chr>        <int>
    ##  1 NJ             146
    ##  2 FL             122
    ##  3 NC             115
    ##  4 WA              97
    ##  5 MD              90
    ##  6 MA              79
    ##  7 TX              71
    ##  8 NY              65
    ##  9 SC              63
    ## 10 CO              59
    ## # ... with 41 more rows

There are 404 unique locations in this dataset, and every state is represented. New Jersey is observed the most.

**In 2002, what is the median of the “Excellent” response value?**

``` r
structured_brfss_2002 = filter(structured_brfss, year == "2002") 
median(structured_brfss_2002$excellent, na.rm = TRUE)
```

    ## [1] 23.6

The median of the "Excellent" response is 23.6

**Make a histogram of “Excellent” response values in the year 2002.**

``` r
ggplot(structured_brfss_2002, aes(x = excellent)) +
  geom_histogram(binwidth = 1.5,na.rm = T) +
  labs(
    title = "Excellent response values histogram",
    x = "Excellent response values in the year of 2002",
    y = "Number"
  )
```

![](p8105_hw2_sy2824_files/figure-markdown_github/unnamed-chunk-14-1.png)

**Make a scatterplot showing the proportion of “Excellent” response values**

``` r
filter(structured_brfss, 
       locationdesc == "NY - New York County" | locationdesc == "NY - Queens County") %>% 
ggplot(aes(x = year, y = excellent/sum, color = locationdesc)) +
  geom_point(alpha = .5) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Excellent proportion scatterplot",
    x = "Year",
    y = "Proportion of Excellent responses values"
  ) +
  theme(legend.position = "bottom")
```

![](p8105_hw2_sy2824_files/figure-markdown_github/unnamed-chunk-15-1.png)
